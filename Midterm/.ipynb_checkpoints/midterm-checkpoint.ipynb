{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from below:\n",
    "# https://cseweb.ucsd.edu/classes/fa21/cse258-b/files/\n",
    "dataset = list(parse(\"trainRecipes.json.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[:150000]\n",
    "valid = dataset[150000:175000]\n",
    "test = dataset[175000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'double delicious cookie bars',\n",
       " 'minutes': 40,\n",
       " 'contributor_id': '26865936',\n",
       " 'submitted': '2007-08-27',\n",
       " 'steps': 'preheat oven to 350f\\tin 13x9-inch baking pan , melt butter in oven\\tsprinkle crumbs evenly over butter\\tpour milk evenly over crumbs\\ttop with remaining ingredients\\tpress down firmly\\tbake 25-30 minutes or until lightly browned\\tcool completely , chill if desired , and cut into bars',\n",
       " 'description': 'from \"all time favorite recipes\". for fun, try substituting butterscotch or white chocolate chips for the semi-sweet and/or peanut butter chips. make sure you cool it completely or the bottom will crumble!',\n",
       " 'ingredients': ['butter',\n",
       "  'graham cracker crumbs',\n",
       "  'sweetened condensed milk',\n",
       "  'semi-sweet chocolate chips',\n",
       "  'peanut butter chips'],\n",
       " 'recipe_id': '98015212'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat1a(d):\n",
    "    features = []\n",
    "    for datum in d:\n",
    "        features.append([len(datum['steps']), len(datum['ingredients'])])\n",
    "    return np.asarray(features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat1b(d):\n",
    "    features = []\n",
    "    \n",
    "    t = [dateutil.parser.parse(datum['submitted']) for datum in d]\n",
    "    t_years = [[day.year] for day in t]\n",
    "    t_months = [[day.month] for day in t]\n",
    "    enc = OneHotEncoder(drop='first', handle_unknown='error')\n",
    "    month_onehot = enc.fit_transform(t_months).toarray()\n",
    "    year_onehot = enc.fit_transform(t_years).toarray()\n",
    "    \n",
    "    return np.hstack((month_onehot, year_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopIngredients(d = dataset):\n",
    "    ingredientDict = defaultdict(int)\n",
    "\n",
    "    for datum in d:\n",
    "        for ingredient in datum['ingredients']:\n",
    "            ingredientDict[ingredient] += 1\n",
    "\n",
    "    topIngredientsList = []\n",
    "    for key in ingredientDict:\n",
    "        topIngredientsList.append((key, ingredientDict[key]))\n",
    "\n",
    "    topIngredientsList = sorted(topIngredientsList, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return topIngredientsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat1c(d):\n",
    "    features = []\n",
    "    \n",
    "    topIngredientsList = getTopIngredients()[:50]\n",
    "    \n",
    "    ingredientSet = defaultdict(int)\n",
    "    for i in range(len(topIngredientsList)):\n",
    "        ingredientSet[topIngredientsList[i][0]] = i\n",
    "    \n",
    "    for datum in d:\n",
    "        tempVec = [0]*50\n",
    "        for ingredient in datum['ingredients']:\n",
    "            if ingredient in ingredientSet:\n",
    "                tempVec[ingredientSet[ingredient]] = 1\n",
    "        features.append(tempVec)\n",
    "    \n",
    "    return np.asarray(features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeFeatures(features, temp):\n",
    "    if features.size == 0:\n",
    "        return temp\n",
    "    else:\n",
    "        return np.hstack((features, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(d, a = True, b = True, c = True):\n",
    "    # Hint: for Questions 1 and 2, might be useful to set up a function like this\n",
    "    #       which allows you to \"select\" which features are included\n",
    "    \n",
    "    features = np.array([])\n",
    "    if a:\n",
    "        features = mergeFeatures(features, feat1a(d))\n",
    "    if b:\n",
    "        features = mergeFeatures(features, feat1b(d))\n",
    "    if c:\n",
    "        features = mergeFeatures(features, feat1c(d))\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    # Can use library if you prefer\n",
    "    return mean_squared_error(y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(d):\n",
    "    return np.asarray([datum['minutes'] for datum in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(mod, a = True, b = True, c = True):\n",
    "    # Hint: might be useful to write this function which extracts features and \n",
    "    #       computes the performance of a particular model on those features\n",
    "    train_feat = feat(train, a, b, c)\n",
    "    test_feat = feat(test, a, b, c)\n",
    "    y_train = getLabels(train)\n",
    "    print('first features: ', train_feat[0])\n",
    "    mod.fit(train_feat, y_train)\n",
    "    y_pred_test = mod.predict(test_feat)\n",
    "    y_test = getLabels(test)\n",
    "    print('MSE: ', MSE(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1A: \n",
      "first features:  [743 9]\n",
      "MSE:  6169.549296366498\n",
      "\n",
      "Model 1B: \n",
      "first features:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "MSE:  6396.833687711815\n",
      "\n",
      "Model 1C: \n",
      "first features:  [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "MSE:  6000.948439855976\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "print('Model 1A: ')\n",
    "experiment(model, b = False, c = False)\n",
    "print('\\nModel 1B: ')\n",
    "experiment(model, a = False, c = False)\n",
    "print('\\nModel 1C: ')\n",
    "experiment(model, b = False, a = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ablation Model 1A: \n",
      "first features:  [0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "MSE:  5992.663510100702\n",
      "\n",
      "Ablation Model 1B: \n",
      "first features:  [743 9 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "MSE:  5870.115061656059\n",
      "\n",
      "Ablation Model 1C: \n",
      "first features:  [743 9 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      "MSE:  6157.754094366206\n",
      "\n",
      "Ablation Model Full: \n",
      "first features:  [743 9 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "MSE:  5861.2539056713895\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "print('Ablation Model 1A: ')\n",
    "experiment(model, a = False)\n",
    "print('\\nAblation Model 1B: ')\n",
    "experiment(model, b = False)\n",
    "print('\\nAblation Model 1C: ')\n",
    "experiment(model, c = False)\n",
    "print('\\nAblation Model Full: ')\n",
    "experiment(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "By removing feature C, we get the largest increase in MSE, thus we \n",
      "can argue that feature C is an important feature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "By removing feature C, we get the largest increase in MSE, thus we \n",
    "can argue that feature C is an important feature\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE is a poor choice of loss in datasets that have significant outliers \n",
      "because the predictor may be dominated by a few very long cooking times \n",
      "in the 8+ hour range. By using MSE we try to force the model to also be \n",
      "a good predictor for these outliers that are not representative of the data\n",
      "\n",
      "1) Transforming the output variable such that y_new = log(y)\n",
      "2) Simply delete outlying instances from dataset by defining some range \n",
      "    [y_min, y_max] and discarding all instances (x, y) outside of that range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "MSE is a poor choice of loss in datasets that have significant outliers \n",
    "because the predictor may be dominated by a few very long cooking times \n",
    "in the 8+ hour range. By using MSE we try to force the model to also be \n",
    "a good predictor for these outliers that are not representative of the data\n",
    "\n",
    "1) Transforming the output variable such that y_new = log(y)\n",
    "2) Simply delete outlying instances from dataset by defining some range \n",
    "    [y_min, y_max] and discarding all instances (x, y) outside of that range\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BER(predictions, y):\n",
    "    # Implement following this logic or otherwise\n",
    "    TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "    FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "    FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "    \n",
    "    #TN, FP, FN, TP = confusion_matrix(y, predictions).ravel()\n",
    "    \n",
    "    FPR = FP/(FP + TN)\n",
    "    FNR = FN/(FN + TP)\n",
    "    \n",
    "    \n",
    "    return (FPR + FNR) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopIngredientsSansButter(d = dataset):\n",
    "    ingredientDict = defaultdict(int)\n",
    "\n",
    "    for datum in d:\n",
    "        for ingredient in datum['ingredients']:\n",
    "            ingredientDict[ingredient] += 1\n",
    "\n",
    "    topIngredientsList = []\n",
    "    for key in ingredientDict:\n",
    "        if key == 'butter':\n",
    "            continue\n",
    "        topIngredientsList.append((key, ingredientDict[key]))\n",
    "\n",
    "    topIngredientsList = sorted(topIngredientsList, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return topIngredientsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat2(d, dict_size, mostPopularInd):\n",
    "    features = []\n",
    "    for datum in d:\n",
    "        fIng = [0] * dict_size\n",
    "        for i in datum['ingredients']:\n",
    "            if i == 'butter':\n",
    "                continue\n",
    "            if i in mostPopularInd:\n",
    "                fIng[mostPopularInd[i]] = 1\n",
    "        features.append(fIng)\n",
    "    return np.asarray(features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getButterLabel(d):\n",
    "    y = []\n",
    "    for datum in d:\n",
    "        foundButter = False\n",
    "        for ingredient in datum['ingredients']:\n",
    "            if ingredient == 'butter':\n",
    "                foundButter = True\n",
    "                break;\n",
    "        if foundButter:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    return np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(reg = 1, dict_size = 50, report_train=False, report_valid=False, report_test=False):\n",
    "    # Hint: run an experiment with a particular regularization strength, and a particular one-hot encoding size\n",
    "    # extract features...\n",
    "    topIngredientsList = getTopIngredientsSansButter()[:dict_size]\n",
    "    \n",
    "    ingredientSet = defaultdict(int)\n",
    "    for i in range(len(topIngredientsList)):\n",
    "        ingredientSet[topIngredientsList[i][0]] = i\n",
    "    \n",
    "    feat_train = feat2(train, dict_size, ingredientSet)\n",
    "    y_train = getButterLabel(train)\n",
    "\n",
    "    mod = linear_model.LogisticRegression(C=reg, class_weight='balanced', solver = 'lbfgs')\n",
    "    mod.fit(feat_train, y_train)\n",
    "\n",
    "    feat_valid = feat2(valid, dict_size, ingredientSet)\n",
    "    y_valid = getButterLabel(valid)\n",
    "    y_valid_pred = mod.predict(feat_valid)\n",
    "    \n",
    "    if report_train:\n",
    "        y_train_pred = mod.predict(feat_train)\n",
    "        print('Train BER: ', BER(y_train_pred, y_train))\n",
    "    \n",
    "    if report_valid:\n",
    "        print('Validation BER: ', BER(y_valid_pred, y_valid))\n",
    "    \n",
    "    if report_test:\n",
    "        feat_test = feat2(test, dict_size, ingredientSet)\n",
    "        y_test = getButterLabel(test)\n",
    "        y_test_pred = mod.predict(feat_test)\n",
    "\n",
    "        print('Test BER: ', BER(y_test_pred, y_test))\n",
    "    \n",
    "    return mod, BER(y_valid_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER:  0.28930328282968243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=1, class_weight='balanced'), 0.28951737136608635)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(report_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    BER = 1\n",
    "    for reg in [0.01, 1, 100]:\n",
    "        for dsize in [50, 100, 200]:\n",
    "            # Example values, can pick any others...\n",
    "            print('reg: {}, dsize: {}'.format(reg, dsize))\n",
    "            _, temp_ber = experiment(reg=reg, dict_size=dsize, report_train=True, report_valid=True)\n",
    "            \n",
    "            if BER > temp_ber:\n",
    "                c_opt = reg\n",
    "                d_opt = dsize\n",
    "            print()\n",
    "    \n",
    "    print('Optimum model: ')\n",
    "    experiment(reg=c_opt, dict_size=d_opt, report_test=True)\n",
    "    \n",
    "    return c_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg: 0.01, dsize: 50\n",
      "Train BER:  0.2901895036037755\n",
      "Validation BER:  0.29033267701492\n",
      "\n",
      "reg: 0.01, dsize: 100\n",
      "Train BER:  0.26404572820163397\n",
      "Validation BER:  0.26473200940198605\n",
      "\n",
      "reg: 0.01, dsize: 200\n",
      "Train BER:  0.24644410101153835\n",
      "Validation BER:  0.2461171573321106\n",
      "\n",
      "reg: 1, dsize: 50\n",
      "Train BER:  0.2898832003476495\n",
      "Validation BER:  0.28951737136608635\n",
      "\n",
      "reg: 1, dsize: 100\n",
      "Train BER:  0.2621956833656805\n",
      "Validation BER:  0.2644673467541458\n",
      "\n",
      "reg: 1, dsize: 200\n",
      "Train BER:  0.24338886530751214\n",
      "Validation BER:  0.2453328273275703\n",
      "\n",
      "reg: 100, dsize: 50\n",
      "Train BER:  0.289919044614668\n",
      "Validation BER:  0.28951737136608635\n",
      "\n",
      "reg: 100, dsize: 100\n",
      "Train BER:  0.26220723251465694\n",
      "Validation BER:  0.26441473732653636\n",
      "\n",
      "reg: 100, dsize: 200\n",
      "Train BER:  0.24332036088407077\n",
      "Validation BER:  0.2451614076906133\n",
      "\n",
      "Optimum model: \n",
      "Test BER:  0.24564315945337192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 200)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 (Recommender Systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility data structures\n",
    "ingsPerItem = defaultdict(set)\n",
    "itemsPerIng = defaultdict(set)\n",
    "recipeNameMapping = defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    r = d['recipe_id']\n",
    "    recipeNameMapping[d['recipe_id']] = d['name']\n",
    "    for i in d['ingredients']:\n",
    "        ingsPerItem[r].add(i)\n",
    "        itemsPerIng[i].add(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarRecipes(recipe, N):\n",
    "    similarities = []\n",
    "    ingredients = ingsPerItem[recipe]\n",
    "    for i2 in ingsPerItem:\n",
    "        if i2 == recipe: continue\n",
    "        sim = Jaccard(ingredients, ingsPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendedRecipes = mostSimilarRecipes('06432987', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4166666666666667, '68523854'),\n",
       " (0.38461538461538464, '12679596'),\n",
       " (0.36363636363636365, '79675099'),\n",
       " (0.36363636363636365, '56301588'),\n",
       " (0.35714285714285715, '87359281')]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendedRecipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chez panisse zucchini fritters\n",
      "red wine steak and mushrooms\n",
      "warm mushroom and romaine salad\n",
      "family favorite salad dressing\n",
      "fresh tomato garden pasta\n"
     ]
    }
   ],
   "source": [
    "for item in recommendedRecipes:\n",
    "    print(recipeNameMapping[item[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarIngredients(ingredient, N):\n",
    "    similarities = []\n",
    "    recipes = itemsPerIng[ingredient]\n",
    "    for ing in itemsPerIng:\n",
    "        if ing == ingredient: continue\n",
    "        sim = Jaccard(recipes, itemsPerIng[ing])\n",
    "        similarities.append((sim, ing))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.22315311514274808, 'salt'),\n",
       " (0.2056685424969639, 'flour'),\n",
       " (0.19100394157199166, 'eggs'),\n",
       " (0.17882420717656095, 'sugar'),\n",
       " (0.17040052045973944, 'milk')]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarIngredients('butter', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Define a similarity threshold till which we'll find similar \n",
      "ingredients of each ingredient in the list provided. Then we \n",
      "make an expanded list of all of these ingredients and find the \n",
      "recipe that has ingredients most similar to these ingredients.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Define a similarity threshold till which we'll find similar \n",
    "ingredients of each ingredient in the list provided. Then we \n",
    "make an expanded list of all of these ingredients and find the \n",
    "recipe that has ingredients most similar to these ingredients.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostEssence_ialRecipes(ingredients, similarity_threshold, N): #Get it? I'll show myself out ->\n",
    "    similar_ingredients = []\n",
    "    for ingredient in ingredients:\n",
    "        temp = mostSimilarIngredients(ingredient, similarity_threshold)\n",
    "        similar_ingredients.extend([item[1] for item in temp])\n",
    "        similar_ingredients.append(ingredient)\n",
    "    \n",
    "    similar_ingredients = set(similar_ingredients)\n",
    "    similarities = []\n",
    "    for i2 in ingsPerItem:\n",
    "        sim = Jaccard(similar_ingredients, ingsPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendedRecipes = mostEssence_ialRecipes({'cinnamon', 'cherries', 'butterscotch', 'vodka'}, \n",
    "                                            similarity_threshold=2, \n",
    "                                            N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.23076923076923078, '25952034'),\n",
       " (0.23076923076923078, '15152859'),\n",
       " (0.21428571428571427, '34731021'),\n",
       " (0.21428571428571427, '32115995'),\n",
       " (0.21428571428571427, '02927915')]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendedRecipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlas\n",
      "sea breezes\n",
      "sex on the moon\n",
      "nola blue glacier martini\n",
      "rangoon ruby cocktail\n"
     ]
    }
   ],
   "source": [
    "for item in recommendedRecipes:\n",
    "    print(recipeNameMapping[item[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python cse258",
   "language": "python",
   "name": "cse258"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
