{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    for l in c:\n",
    "        d = dict(zip(header,l))\n",
    "        yield d['user_id'],d['recipe_id'],d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    dataset = []\n",
    "    for line in c:\n",
    "        d = dict(zip(header, line))\n",
    "        dataset.append(d)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadCSV('trainInteractions.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '88348277', 'recipe_id': '03969194', 'date': '2004-12-23', 'rating': '5'}\n"
     ]
    }
   ],
   "source": [
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "\n",
    "for user,recipe,d in readCSV(\"trainInteractions.csv.gz\"):\n",
    "    print(d)\n",
    "    recipeCount[recipe] += 1\n",
    "    totalCooked += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[:400000]\n",
    "validation = dataset[400000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "userPerRecipeValid = defaultdict(set)\n",
    "recipePerUserValid = defaultdict(set)\n",
    "recipeListValid = set([])\n",
    "newValidationDataset = []\n",
    "\n",
    "for datum in validation:\n",
    "    user, recipe = datum['user_id'], datum['recipe_id']\n",
    "    userPerRecipeValid[recipe].add(user)\n",
    "    recipePerUserValid[user].add(recipe)\n",
    "    recipeListValid.add(recipe)\n",
    "\n",
    "recipeListValid = list(recipeListValid)\n",
    "recipeListSize = len(recipeListValid)\n",
    "for datum in validation:\n",
    "    user, recipe = datum['user_id'], datum['recipe_id']\n",
    "    newValidationDataset.append((user, recipe, 1))\n",
    "    \n",
    "    while True:\n",
    "        index = random.randint(0, recipeListSize - 1)\n",
    "        if recipeListValid[index] not in recipePerUserValid[user]:\n",
    "            break\n",
    "    \n",
    "    newValidationDataset.append((user, recipeListValid[index], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newValidationDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('90764166', '01768679', 1),\n",
       " ('90764166', '44845944', 0),\n",
       " ('68112239', '24923981', 1),\n",
       " ('68112239', '64197312', 0),\n",
       " ('32173358', '57597698', 1),\n",
       " ('32173358', '58861769', 0),\n",
       " ('30893740', '16266088', 1),\n",
       " ('30893740', '78236641', 0),\n",
       " ('69780905', '62953151', 1),\n",
       " ('69780905', '28584315', 0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newValidationDataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-cook baseline: just rank which recipes are popular and which are not, and return '1' if a recipe is among the top-ranked\n",
    "\n",
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "\n",
    "for d in train:\n",
    "    user, recipe = d['user_id'], d['recipe_id']\n",
    "    recipeCount[recipe] += 1\n",
    "    totalCooked += 1\n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalCooked/2: break\n",
    "\n",
    "correct_labels = 0\n",
    "total_labels = 0\n",
    "for d in newValidationDataset:\n",
    "    user, recipe, label = d\n",
    "    if recipe in return1:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "    \n",
    "    if prediction == label:\n",
    "        correct_labels += 1\n",
    "    total_labels += 1\n",
    "\n",
    "accuracy = correct_labels/total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61539"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.43, 0.45, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.55, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.54484\n",
      "0.2 0.580665\n",
      "0.3 0.603475\n",
      "0.4 0.613305\n",
      "0.43 0.61458\n",
      "0.45 0.614885\n",
      "0.48 0.61494\n",
      "0.49 0.614555\n",
      "0.5 0.61443\n",
      "0.51 0.613975\n",
      "0.52 0.61404\n",
      "0.53 0.613185\n",
      "0.55 0.61228\n",
      "0.6 0.60929\n",
      "0.7 0.599965\n",
      "0.8 0.58739\n",
      "0.9 0.570195\n"
     ]
    }
   ],
   "source": [
    "### Would-cook baseline: just rank which recipes are popular and which are not, and return '1' if a recipe is among the top-ranked\n",
    "\n",
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "best_accuracy = 0\n",
    "better_threshold = 0\n",
    "\n",
    "for d in train:\n",
    "    user, recipe = d['user_id'], d['recipe_id']\n",
    "    recipeCount[recipe] += 1\n",
    "    totalCooked += 1\n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "for threshold in thresholds:\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > (totalCooked * threshold): \n",
    "            break\n",
    "\n",
    "    correct_labels = 0\n",
    "    total_labels = 0\n",
    "    for d in newValidationDataset:\n",
    "        user, recipe, label = d\n",
    "        if recipe in return1:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = 0\n",
    "\n",
    "        if prediction == label:\n",
    "            correct_labels += 1\n",
    "        total_labels += 1\n",
    "\n",
    "    accuracy = correct_labels/total_labels\n",
    "    print(threshold, accuracy)\n",
    "    if best_accuracy < accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        better_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61494\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)\n",
    "print(better_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "userPerRecipeTrain = defaultdict(set)\n",
    "recipePerUserTrain = defaultdict(set)\n",
    "\n",
    "for datum in train:\n",
    "    user, recipe = datum['user_id'], datum['recipe_id']\n",
    "    userPerRecipeTrain[recipe].add(user)\n",
    "    recipePerUserTrain[user].add(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(recipe, N):\n",
    "    similarities = []\n",
    "    users = userPerRecipeTrain[recipe]\n",
    "    for i2 in userPerRecipeTrain:\n",
    "        if i2 == i: continue\n",
    "        sim = Jaccard(users, userPerRecipeTrain[i2])\n",
    "\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_thresholds = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('90764166', '01768679', 1), ('90764166', '44845944', 0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newValidationDataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.596115\n",
      "0.1 0.521945\n",
      "0.2 0.514155\n",
      "0.3 0.5076\n",
      "0.4 0.502215\n",
      "0.5 0.498775\n",
      "0.6 0.49875\n",
      "0.7 0.49865\n",
      "0.8 0.498645\n",
      "0.9 0.498645\n",
      "0.95 0.498645\n",
      "0.596115 0.0\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_threshold = 0\n",
    "for sim_threshold in sim_thresholds:\n",
    "    correct_labels = 0\n",
    "    total_labels = 0\n",
    "    for d in newValidationDataset:\n",
    "        user, recipe, label = d\n",
    "        \n",
    "        prediction = 0\n",
    "        for userRecipe in recipePerUserTrain[user]:\n",
    "            if Jaccard(userPerRecipeTrain[recipe], userPerRecipeTrain[userRecipe]) > sim_threshold:\n",
    "                prediction = 1\n",
    "                break\n",
    "\n",
    "        if prediction == label:\n",
    "            correct_labels += 1\n",
    "        total_labels += 1\n",
    "\n",
    "    accuracy = correct_labels/total_labels\n",
    "    print(sim_threshold, accuracy)\n",
    "    if best_accuracy < accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = sim_threshold\n",
    "\n",
    "print(best_accuracy, best_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_threshold = 0.48\n",
    "sim_threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-cook baseline: just rank which recipes are popular and which are not, and return '1' if a recipe is among the top-ranked\n",
    "\n",
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "best_accuracy = 0\n",
    "better_threshold = 0\n",
    "\n",
    "for d in train:\n",
    "    user, recipe = d['user_id'], d['recipe_id']\n",
    "    recipeCount[recipe] += 1\n",
    "    totalCooked += 1\n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > (totalCooked * popularity_threshold): \n",
    "        break\n",
    "        \n",
    "correct_labels = 0\n",
    "total_labels = 0\n",
    "for d in newValidationDataset:\n",
    "    user, recipe, label = d\n",
    "\n",
    "    prediction = 0\n",
    "    if recipe in return1:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        for userRecipe in recipePerUserTrain[user]:\n",
    "            if Jaccard(userPerRecipeTrain[recipe], userPerRecipeTrain[userRecipe]) > sim_threshold:\n",
    "                prediction = 1\n",
    "                break\n",
    "\n",
    "    if prediction == label:\n",
    "        correct_labels += 1\n",
    "    total_labels += 1\n",
    "\n",
    "accuracy = correct_labels/total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62531\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-cook baseline: just rank which recipes are popular and which are not, and return '1' if a recipe is among the top-ranked\n",
    "\n",
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "best_accuracy = 0\n",
    "better_threshold = 0\n",
    "\n",
    "for d in train:\n",
    "    user, recipe = d['user_id'], d['recipe_id']\n",
    "    recipeCount[recipe] += 1\n",
    "    totalCooked += 1\n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > (totalCooked * popularity_threshold): \n",
    "        break\n",
    "        \n",
    "correct_labels = 0\n",
    "total_labels = 0\n",
    "\n",
    "predictions = open(\"predictions_Made.txt\", 'w')\n",
    "for l in open(\"stub_Made.txt\"):\n",
    "    if l.startswith(\"user_id\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    user, recipe = l.strip().split('-')\n",
    "    \n",
    "    prediction = 0\n",
    "    if recipe in return1:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        for userRecipe in recipePerUserTrain[user]:\n",
    "            if Jaccard(userPerRecipeTrain[recipe], userPerRecipeTrain[userRecipe]) > sim_threshold:\n",
    "                prediction = 1\n",
    "                break\n",
    "    predictions.write(user + '-' + recipe + ',' + str(prediction) + '\\n')\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Username: vktiwari33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user,recipe,d in readCSV(\"trainInteractions.csv.gz\"):\n",
    "    d['rating'] = int(d['rating'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[:400000]\n",
    "valid = dataset[400000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train:\n",
    "    user,item = d['user_id'], d['recipe_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingMean = sum([d['rating'] for d in train]) / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [d['rating'] for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    if user not in userBiases or item not in itemBiases:\n",
    "        return alpha\n",
    "    return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, dataset, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d['user_id'], d['recipe_id']) for d in dataset]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, dataset, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(dataset)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for d in dataset:\n",
    "        u,i = d['user_id'], d['recipe_id']\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d['rating']\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.898807042703075\n",
      "MSE = 1.4092942879265038\n",
      "MSE = 0.8985950192911197\n",
      "MSE = 0.8985951779117449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 4.58067353e+00, -8.58146680e-05, -8.06156759e-06, ...,\n",
       "        -1.45132190e-06,  1.04630213e-06, -1.45114646e-06]),\n",
       " 0.8986631878445489,\n",
       " {'grad': array([-6.61797442e-06,  2.22831645e-07,  6.45420112e-09, ...,\n",
       "          6.22533785e-10,  9.15110290e-10,  6.22405709e-10]),\n",
       "  'task': 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'funcalls': 4,\n",
       "  'nit': 2,\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, \n",
    "                             [alpha] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, \n",
    "                             args = (labels, train, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094423694728887\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "y_pred = []\n",
    "for d in valid:\n",
    "    y.append(d['rating'])\n",
    "    y_pred.append(prediction(d['user_id'], d['recipe_id']))\n",
    "\n",
    "print(MSE(y_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestBu = -100000\n",
    "largestBuUser = None\n",
    "smallestBu = 100000\n",
    "smallestBuUser = None\n",
    "\n",
    "for u in userBiases:\n",
    "    if largestBu < userBiases[u]: \n",
    "        largestBu = userBiases[u]\n",
    "        largestBuUser = u\n",
    "    if smallestBu > userBiases[u]:\n",
    "        smallestBu = userBiases[u]\n",
    "        smallestBuUser = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestBi = -100000\n",
    "largestBiItem = None\n",
    "smallestBi = 100000\n",
    "smallestBiItem = None\n",
    "\n",
    "for i in itemBiases:\n",
    "    if largestBi < itemBiases[i]: \n",
    "        largestBi = itemBiases[i]\n",
    "        largestBiItem = i\n",
    "    if smallestBi > itemBiases[i]:\n",
    "        smallestBi = itemBiases[i]\n",
    "        smallestBiItem = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32445558 70705426\n"
     ]
    }
   ],
   "source": [
    "print(largestBuUser, smallestBuUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98124873 29147042\n"
     ]
    }
   ],
   "source": [
    "print(largestBiItem, smallestBiItem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.9041522520298038\n",
      "MSE = 0.9065746152135636\n",
      "MSE = 0.9041644373852212\n",
      "MSE = 0.9041532582922053\n",
      "MSE = 0.9041524159379389\n",
      "MSE = 0.9041522845253479\n",
      "MSE = 0.904152258774527\n",
      "MSE = 0.9041522534442399\n",
      "MSE = 0.9041522523276956\n",
      "MSE = 0.9041522520932328\n",
      "MSE = 0.904152252043906\n",
      "MSE = 0.9041522520335278\n",
      "MSE = 0.9041522520315187\n",
      "MSE = 0.9041522520309915\n",
      "MSE = 0.9041522520313834\n",
      "MSE = 0.9041522520302345\n",
      "MSE = 0.9041522520298881\n",
      "MSE = 0.9041522520298035\n",
      "MSE = 0.9041522520298643\n",
      "MSE = 0.9041522520298143\n",
      "MSE = 0.9041522520298074\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9065746152135092\n",
      "MSE = 0.9041555532702313\n",
      "MSE = 0.9041526078893113\n",
      "MSE = 0.9041523169186456\n",
      "MSE = 0.9041522652635642\n",
      "MSE = 0.9041522547942986\n",
      "MSE = 0.9041522526107004\n",
      "MSE = 0.9041522521529763\n",
      "MSE = 0.9041522520565711\n",
      "MSE = 0.9041522520366437\n",
      "MSE = 0.9041522520322104\n",
      "MSE = 0.9041522520310568\n",
      "MSE = 0.9041522520313223\n",
      "MSE = 0.9041522520305507\n",
      "MSE = 0.9041522520301756\n",
      "MSE = 0.9041522520298223\n",
      "MSE = 0.9041522520298042\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9065746152135092\n",
      "MSE = 0.9041540207302252\n",
      "MSE = 0.9041524668612461\n",
      "MSE = 0.9041522925412301\n",
      "MSE = 0.9041522603543722\n",
      "MSE = 0.9041522537719409\n",
      "MSE = 0.9041522523967173\n",
      "MSE = 0.9041522521077934\n",
      "MSE = 0.9041522520467854\n",
      "MSE = 0.9041522520341442\n",
      "MSE = 0.9041522520316282\n",
      "MSE = 0.9041522520312912\n",
      "MSE = 0.9041522520314996\n",
      "MSE = 0.9041522520302949\n",
      "MSE = 0.9041522520299464\n",
      "MSE = 0.9041522520298103\n",
      "MSE = 0.9041522520298042\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9065746152135092\n",
      "MSE = 0.9041534347111018\n",
      "MSE = 0.904152405719145\n",
      "MSE = 0.9041522814849793\n",
      "MSE = 0.9041522581038378\n",
      "MSE = 0.904152253302161\n",
      "MSE = 0.9041522522982086\n",
      "MSE = 0.9041522520868578\n",
      "MSE = 0.9041522520426897\n",
      "MSE = 0.904152252033688\n",
      "MSE = 0.9041522520315791\n",
      "MSE = 0.9041522520310344\n",
      "MSE = 0.9041522520311678\n",
      "MSE = 0.9041522520301998\n",
      "MSE = 0.9041522520298814\n",
      "MSE = 0.9041522520298074\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9065746152135092\n",
      "MSE = 0.904153133219285\n",
      "MSE = 0.9041523716287377\n",
      "MSE = 0.9041522751713155\n",
      "MSE = 0.9041522568119852\n",
      "MSE = 0.9041522530319033\n",
      "MSE = 0.9041522522412934\n",
      "MSE = 0.9041522520750892\n",
      "MSE = 0.9041522520403055\n",
      "MSE = 0.9041522520327495\n",
      "MSE = 0.9041522520316795\n",
      "MSE = 0.904152252030761\n",
      "MSE = 0.9041522520309839\n",
      "MSE = 0.9041522520301375\n",
      "MSE = 0.9041522520298663\n",
      "MSE = 0.904152252029807\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9065746152135092\n",
      "MSE = 0.9041529515927808\n",
      "MSE = 0.9041523499027238\n",
      "MSE = 0.9041522710871008\n",
      "MSE = 0.9041522559732982\n",
      "MSE = 0.904152252856751\n",
      "MSE = 0.904152252204452\n",
      "MSE = 0.9041522520674329\n",
      "MSE = 0.9041522520385419\n",
      "MSE = 0.9041522520328005\n",
      "MSE = 0.9041522520311526\n",
      "MSE = 0.9041522520311877\n",
      "MSE = 0.90415225203079\n",
      "MSE = 0.9041522520301768\n",
      "MSE = 0.9041522520298491\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.9065746152135092\n",
      "MSE = 0.9041528856896582\n",
      "MSE = 0.9041523417507212\n",
      "MSE = 0.9041522695417088\n",
      "MSE = 0.9041522556554337\n",
      "MSE = 0.9041522527899962\n",
      "MSE = 0.9041522521906193\n",
      "MSE = 0.9041522520642553\n",
      "MSE = 0.9041522520379054\n",
      "MSE = 0.9041522520324655\n",
      "MSE = 0.9041522520314891\n",
      "MSE = 0.9041522520311882\n",
      "MSE = 0.9041522520307488\n",
      "MSE = 0.9041522520301949\n",
      "MSE = 0.904152252029843\n",
      "MSE = 0.9041522520298042\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.9041522520298041\n",
      "MSE = 0.904152252029804\n",
      "MSE = 0.904152252029804\n"
     ]
    }
   ],
   "source": [
    "min_mse = 100000\n",
    "opt_lamb = None\n",
    "for lamb in lambdas:\n",
    "    _, mse, _ = scipy.optimize.fmin_l_bfgs_b(cost, \n",
    "                                 [alpha] + [0.0]*(nUsers+nItems),\n",
    "                                 derivative, \n",
    "                                 args = (labels, valid, lamb))\n",
    "    if min_mse > mse:\n",
    "        min_mse = mse\n",
    "        opt_lamb = lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904152252029804\n",
      "1.2\n"
     ]
    }
   ],
   "source": [
    "print(min_mse)\n",
    "print(opt_lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.8987313676875054\n",
      "MSE = 0.8861891996778084\n",
      "MSE = 0.9367774454503509\n",
      "MSE = 0.8854927942747061\n",
      "MSE = 0.8896541050782545\n",
      "MSE = 0.8888137440324333\n",
      "MSE = 0.8888688677704336\n",
      "MSE = 0.8888662342932155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 4.57210042e+00, -3.89869928e-03, -6.25858145e-04, ...,\n",
       "        -1.13793643e-04,  7.19411161e-05, -1.12289754e-04]),\n",
       " 0.8933592826848815,\n",
       " {'grad': array([-2.94641129e-06, -1.58627819e-07,  2.83147152e-08, ...,\n",
       "          5.90888053e-09, -3.85861981e-09,  3.81020327e-09]),\n",
       "  'task': 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'funcalls': 8,\n",
       "  'nit': 6,\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, \n",
    "                             [alpha] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, \n",
    "                             args = (labels, dataset, 1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rated.txt\", 'w')\n",
    "for l in open(\"stub_Rated.txt\"):\n",
    "    if l.startswith(\"user_id\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    predictions.write(u + '-' + i + ',' + str(prediction(u, i)) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse258",
   "language": "python",
   "name": "cse258"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
